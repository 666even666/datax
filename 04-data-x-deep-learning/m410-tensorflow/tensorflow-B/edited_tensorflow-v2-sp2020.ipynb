{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![data-x](https://raw.githubusercontent.com/afo/data-x-plaksha/master/imgsource/dx_logo.png)\n",
    "\n",
    "---\n",
    "\n",
    "# Data-X: Introduction to TensorFlow v.2\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "**Author List (in no particular order):** [Elias Castro Hernandez](https://www.linkedin.com/in/ehcastroh/), [Rajarathnam Balakrishnan](https://www.linkedin.com/in/rajarathnam-balakrishnan-7b447b135/), [Ikhlaq Sidhu](https://ikhlaq-sidhu.com/), [Debbie Yuen](http://www.debbiecyuen.me/), and [Alexander Fred-Ojala](https://www.linkedin.com/in/alexanderfo/) \n",
    "\n",
    "**Video Walkthrough:** To view walkthrough of this notebook, click [here]()\n",
    "\n",
    "**References and Additional Resources:** See end of this notebook for additional information related to TensorFlow and Keras.\n",
    "\n",
    "**License Agreement:** Feel free to do whatever you want with this code\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "## Tensors and Operations\n",
    "\n",
    "\n",
    "<div align=\"center\" style=\"font-size:12px; font-family:FreeMono; font-weight: 100; font-stretch:ultra-condensed; line-height: 1.0; color:#2A2C2B\">\n",
    "    <img src=\"tensorflow_thumbnail-01.png\" align=\"center\" width=\"40%\" padding=\"10\"><br>\n",
    "    <br>\n",
    "    \n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "[TensorFlow](https://www.tensorflow.org/) is a cross-platform, end-to-end, open source, platform for efficiently training and deploying machine learning models. TensorFlow offers multiple levels of abstractions, which means you can use high-level API's such as [Keras](https://keras.io/) or toolboxes like [Ludwig](https://ludwig-ai.github.io/ludwig-docs/index.html) to make things a bit simpler, or even to set up a [Distribution Strategy](https://www.tensorflow.org/guide/distributed_training) API on different hardware configurions without having to change the model defintion.\n",
    "\n",
    "<br>\n",
    "\n",
    "<strong style=\"color:red\">KEY CONSIDERATION:</strong> Some of the following content may be written for machines running on Linux or Mac operating systems. If you are working on a Windows machine, you will need to enable the Linux Bash Shell, or adjust Shell commands to PowerShell syntax. A tutorial on how to enable the Linux Bash Shell on Windows 10 can be found [here](https://youtu.be/xzgwDbe7foQ)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<br>\n",
    "\n",
    "**Setup TensorFlow**\n",
    "\n",
    "> [TensorFlow V.2](https://www.tensorflow.org/tutorials/quickstart/beginner) removes redundant APIs, and integrates more smoothly with Python via Eager execution. To learn what has changed between versions 1 and 2 of TensorFlow, see [here](https://www.tensorflow.org/guide/effective_tf2). \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pyton 2 and 3 support\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Install TensorFlow:** the following will install TensorFlow using bash. It serves our purposes. However, for detailed installation instructions see the **Additional Resources** section at the end of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Virtual Environment ##\n",
    "! python3 -m venv ./venv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Activate Virtual Environment ##\n",
    "! . ./venv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /home/ehch/anaconda3/lib/python3.6/site-packages (20.1.1)\n"
     ]
    }
   ],
   "source": [
    "## Ensure pip version >= 19.0 ##\n",
    "! pip install --upgrade pip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: tensorflow in /home/ehch/anaconda3/lib/python3.6/site-packages (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /home/ehch/anaconda3/lib/python3.6/site-packages (from tensorflow) (0.9.0)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in /home/ehch/anaconda3/lib/python3.6/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /home/ehch/anaconda3/lib/python3.6/site-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy==1.4.1; python_version >= \"3\" in /home/ehch/.local/lib/python3.6/site-packages (from tensorflow) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /home/ehch/anaconda3/lib/python3.6/site-packages (from tensorflow) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard<2.3.0,>=2.2.0 in /home/ehch/anaconda3/lib/python3.6/site-packages (from tensorflow) (2.2.2)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /home/ehch/anaconda3/lib/python3.6/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /home/ehch/anaconda3/lib/python3.6/site-packages (from tensorflow) (3.12.2)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /home/ehch/anaconda3/lib/python3.6/site-packages (from tensorflow) (1.30.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /home/ehch/anaconda3/lib/python3.6/site-packages (from tensorflow) (0.34.2)\n",
      "Requirement already satisfied, skipping upgrade: gast==0.3.3 in /home/ehch/anaconda3/lib/python3.6/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.3.0,>=2.2.0 in /home/ehch/anaconda3/lib/python3.6/site-packages (from tensorflow) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /home/ehch/anaconda3/lib/python3.6/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /home/ehch/.local/lib/python3.6/site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in /home/ehch/anaconda3/lib/python3.6/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /home/ehch/anaconda3/lib/python3.6/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in /home/ehch/anaconda3/lib/python3.6/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /home/ehch/anaconda3/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.7.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /home/ehch/anaconda3/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /home/ehch/anaconda3/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /home/ehch/.local/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (46.0.0)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /home/ehch/anaconda3/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /home/ehch/anaconda3/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.18.0)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /home/ehch/anaconda3/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.6.11)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /home/ehch/anaconda3/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.2.0)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /home/ehch/.local/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.7)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /home/ehch/.local/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /home/ehch/.local/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2018.10.15)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ehch/.local/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.24.1)\n",
      "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3\" in /home/ehch/.local/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /home/ehch/.local/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.2.3)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /home/ehch/.local/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /home/ehch/anaconda3/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /home/ehch/.local/lib/python3.6/site-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.5)\n"
     ]
    }
   ],
   "source": [
    "## Ensure TF version >= 2.0 ##\n",
    "! pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Import TensorFlow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canonical way of importing TensorFlow\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "**Note:** If ```import tensorflow as tf``` doesn't work, TensorFlow is not installed correctly. To resolve the issue see [build and install error messages](https://www.tensorflow.org/install/errors)\n",
    "    \n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check tf version, oftentimes tensorflow is not backwards compatible\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that Eager Execution is active\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "**Note:** TensorFlow V.2 comes with eager execution enabled by default. Eager mode has many benefits, but for our purposes eager mode allows tensor outputs to be viewed without the need of a session -- which may not be necessary depending on your needs.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## TensorBoard Setup\n",
    "\n",
    "<br>\n",
    "\n",
    "<div align=\"center\" style=\"font-size:12px; font-family:FreeMono; font-weight: 100; font-stretch:ultra-condensed; line-height: 1.0; color:#2A2C2B\">\n",
    "    <img src=\"tensorboard_logo_social.png\" align=\"center\" width=\"30%\" padding=\"0px\"><br>\n",
    "    <br>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "[TensorBoard](https://www.tensorflow.org/tensorboard/get_started) is a tool for measuring and visualizing machine learning workflows. It enables the tracking of important metrics such as [acuracy](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Accuracy), it can display summary operations, tensor ouputs, project embeddings to lower dimensional space, and much more. This broad functionality makes TensorBoard an important tool in evaluating, optimizing, and debugging machine learning models. For a five-minute summary of TensorBoard, click [here](https://youtu.be/3bownM3L5zM).\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Load TensorBoard and Associated Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load TensorBoard notebook extension ##\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load additional libraries needed ##\n",
    "from datetime import datetime\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "t = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\") \n",
    "log_dir = \"tf_logs\"\n",
    "logd = \"/tmp/{}/r{}/\".format(log_dir, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Clear TensorBoard Logs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clear any logs from previous runs ##\n",
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "**Note:** The purpose of this section is only to highlight some of the commands for using TensorBoard. The [MNIST](https://en.wikipedia.org/wiki/MNIST_database) data set used here, is only for the purposes of highlighting functionality which on this case depends on the [Keras](https://keras.io/) library.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Load, split, and create model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Keras datasets import mnist\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# load data into training and testing splits\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# create a sequential model\n",
    "def create_model():\n",
    "  return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "**Note:** Click on the following to learn more about the command:\n",
    ">[```keras.model.sequential( )```](https://keras.io/api/models/sequential/)<br>\n",
    ">[```keras.layers.Flatten( )```](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten)<br>\n",
    ">[```keras.layers.Dense( ) ```](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)<br>\n",
    ">[```keras.layers.Dropout( )```](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout)\n",
    "    \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Compile, and Fit model. Also, add TensorBoard callbacks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.2192 - accuracy: 0.9341 - val_loss: 0.1012 - val_accuracy: 0.9697\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0976 - accuracy: 0.9705 - val_loss: 0.0801 - val_accuracy: 0.9747\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0685 - accuracy: 0.9782 - val_loss: 0.0678 - val_accuracy: 0.9787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9e88503c88>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate model class\n",
    "model = create_model()\n",
    "\n",
    "# compile model \n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# place logs in a timestamped subdirectory and enable histogram computation with every epoch\n",
    "log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "\n",
    "# Fit model\n",
    "model.fit(x=x_train, \n",
    "          y=y_train, \n",
    "          epochs=3, \n",
    "          validation_data=(x_test, y_test), \n",
    "          # Adding 'callbacks=[tensorboard_callback]' to model.fit( ) ensures that logs are created and stored\n",
    "          callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "**Note:** Click on the following to learn more about the command:\n",
    ">[```model.compile( )```](https://keras.io/api/models/model/)<br>\n",
    ">[```callbacks.TensorBoard( )```](https://keras.io/api/callbacks/)<br>\n",
    ">[```model.fit( ) ```](https://keras.io/api/models/model_training_apis/)\n",
    "    \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Display Tensorboard Logs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6008 (pid 2263), started 1:26:10 ago. (Use '!kill 2263' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-dcbe224db119d013\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-dcbe224db119d013\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6008;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## %tensorboard line magic. In command line run same command without \"%\" ##\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "**Note:** if TensorBoard does not load after following the above command, try reloading TensordBoard ```%reload_ext tensorboard``` \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## TensorFlow Tensors\n",
    "\n",
    "<br>\n",
    "\n",
    "<div align=\"center\" style=\"font-size:12px; font-family:FreeMono; font-weight: 100; font-stretch:ultra-condensed; line-height: 1.0; color:#2A2C2B\">\n",
    "    <img src=\"tF_update-03.png\" align=\"center\" width=\"50%\" padding=\"0px\"><br>\n",
    "</div>\n",
    "\n",
    "[Tensors](https://www.tensorflow.org/api_docs/python/tf/Tensor) are immutable multidimensional arrays for working with data with more than 2-Dimensions. Tensors essentially multilinear maps from vector spaces to real numbers. Hence a tensor can be used to represent scalars, vectors, and matrices. Moreover, tensors are [highly efficient](https://realpython.com/numpy-tensorflow-performance/), can be ran on several architectures (CPUs, GPUs, Mobile, and Distributed), and make the calculation of gradients easier -- this is particulary useful as the analytical solution of gradients are extremely tedious to derive. To view the complete list of TensorFlow data types, see [here](https://www.tensorflow.org/api_docs/python/tf/dtypes/DType)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### **tf.constant**\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "[Constants](https://www.tensorflow.org/api_docs/python/tf/constant) are tensors, are initialized directly, and are immutable once created. In order to evaluate them, we used to have to run them in a [session (TF v.1)](https://www.tensorflow.org/api_docs/java/reference/org/tensorflow/Session). In TF v.2, they can be displayed using [eager execution](https://www.tensorflow.org/guide/eager) by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\"font-size:12px; font-family:FreeMono; font-weight: 100; font-stretch:ultra-condensed; line-height: 1.0; color:#2A2C2B\">\n",
    "    <img src=\"tF_update-12.png\" align=\"center\" width=\"40%\" padding=\"0px\"><br>\n",
    "    <br>\n",
    "    Scalar (Rank-0) Tensor\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# int32 tensors by default\n",
    "rank_0_tensor = tf.constant(4)\n",
    "b = tf.constant(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_0_tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensors can also have names (in the computation graph)\n",
    "named_tensor = tf.constant(7.2, name='my_named_tuple')\n",
    "named_tensor.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\"font-size:12px; font-family:FreeMono; font-weight: 100; font-stretch:ultra-condensed; line-height: 1.0; color:#2A2C2B\">\n",
    "    <img src=\"tF_update-11.png\" align=\"center\" width=\"40%\" padding=\"0px\"><br>\n",
    "    <br>\n",
    "    Vector (Rank-1) Tensor\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2. 3. 4.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# float vector tensor\n",
    "rank_1_tensor = tf.constant([2.0, 3.0, 4.0])\n",
    "print(rank_1_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot assign constants\n"
     ]
    }
   ],
   "source": [
    "# Contant Tensors are immutable\n",
    "try:\n",
    "    rank_1_tensor.assign(8)\n",
    "except:\n",
    "    print('Cannot assign constants')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### **tf.Variable**\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A [variable](https://www.tensorflow.org/guide/variable) is the recommended way to represent data manipulated by your program. Variables are usually weights and biases of a model that are optimized during training, they also indicate the degrees of freedom of the model (what model parameters that can change, thus making the model flexible). The following covers how to create, update, and manage instances of [```tf.variable```](https://www.tensorflow.org/api_docs/python/tf/Variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=3.0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create variable tensor\n",
    "var = tf.Variable(3.)\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=4.0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reassign the value of a Variable\n",
    "var.assign(4)\n",
    "var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "**Remark:** why ```tf.constant()``` yet ```tf.Variable()```?  The lowercase ```c``` in ```tf.constant()``` is intended to indicate that tf.constant is an operation, while the captital ```V``` in ```tf.Variable```, is to indicate that it is a class with many operations.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### **Multidimensional Tensors**\n",
    "\n",
    "<div align=\"center\" style=\"font-size:12px; font-family:FreeMono; font-weight: 100; font-stretch:ultra-condensed; line-height: 1.0; color:#2A2C2B\">\n",
    "    <img src=\"tF_update-10.png\" align=\"center\" width=\"40%\" padding=\"0px\"><br>\n",
    "    Matrix (Rank-2) Tensor\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 2.]\n",
      " [3. 4.]\n",
      " [5. 6.]], shape=(3, 2), dtype=float16)\n"
     ]
    }
   ],
   "source": [
    "# tensors can be n-arrays, and we can specity data type\n",
    "rank_2_tensor = tf.constant([[1, 2],\n",
    "                             [3, 4],\n",
    "                             [5, 6]], dtype=tf.float16)\n",
    "print(rank_2_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Build tensors using distributions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(3, 1) dtype=float64, numpy=\n",
       "array([[ 0.34976146],\n",
       "       [-0.8524626 ],\n",
       "       [-0.02533137]])>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can also create multi dim Variables directly\n",
    "c = tf.Variable(np.random.randn(3).reshape(3,1)) #reshape\n",
    "# automatically assings data type\n",
    "c #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Build tensors from Python and NumPy objects**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
       "array([[1., 2.],\n",
       "       [3., 4.]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Altenatively, we can pass Python Lists or NumPy arrays\n",
    "my_tensor = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "my_var = tf.Variable(my_tensor)\n",
    "my_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "name  :  Variable:0\n",
      "\n",
      "type  :  <dtype: 'float32'>\n",
      "\n",
      "shape :  (2, 2)\n",
      "\n",
      "device:  /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\n",
      "As NumPy:  <bound method BaseResourceVariable.numpy of <tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
      "array([[1., 2.],\n",
      "       [3., 4.]], dtype=float32)>>\n"
     ]
    }
   ],
   "source": [
    "# view properties of tensor\n",
    "print('\\nname  : ', my_var.name)\n",
    "print('\\ntype  : ', my_var.dtype)\n",
    "print('\\nshape : ', my_var.shape)\n",
    "print('\\ndevice: ', my_var.device)\n",
    "print(\"\\nAs NumPy: \", my_var.numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Viewed as a tensor: tf.Tensor(\n",
      "[[1. 2.]\n",
      " [3. 4.]], shape=(2, 2), dtype=float32)\n",
      "\n",
      "Index of highest value: tf.Tensor([1 1], shape=(2,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# Tensor operations\n",
    "print(\"\\nViewed as a tensor:\", tf.convert_to_tensor(my_var))\n",
    "print(\"\\nIndex of highest value:\", tf.argmax(my_var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Tensor Variable Assignments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Copying and reshaping (this creates a new tensor):  tf.Tensor([[1. 2. 3. 4.]], shape=(1, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# This creates a new tensor; it does not reshape my_var.\n",
    "print(\"\\nCopying and reshaping (this creates a new tensor): \", tf.reshape(my_var, ([1,4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValueError: Shapes (2,) and (3,) are incompatible\n"
     ]
    }
   ],
   "source": [
    "## Sanity Check ##\n",
    "\n",
    "d = tf.Variable([4.0, 5.5])\n",
    "# This will keep the same dtype, float32\n",
    "d.assign([10, 20]) \n",
    "\n",
    "# Fails, as it resizes the variable \n",
    "try:\n",
    "    d.assign([1.0, 2.0, 3.0])\n",
    "except Exception as exc:\n",
    "    print(f\"{type(exc).__name__}: {exc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "**Note:** Calling ```assign( )``` does not, usually, allocate a new tensor -- instead the tensor's memory is reused.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10. 20.]\n",
      "[10. 20.]\n"
     ]
    }
   ],
   "source": [
    "## Sanity Check ##\n",
    "\n",
    "# Create a new variable based on valued of d\n",
    "e = tf.Variable(d)\n",
    "# make assignment\n",
    "d.assign([10, 20]) \n",
    "\n",
    "# a and b are different\n",
    "print(e.numpy())\n",
    "print(d.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "original value:  3.0\n",
      "\n",
      "assigned value:  10.0\n",
      "\n",
      "add 1: 11.0\n",
      "\n",
      "subtract 5: 6.0\n",
      "\n",
      "Increase/Decrease values in arrays\n",
      "original value:  [10. 20.]\n",
      "\n",
      "add [1,4]:  [11. 24.]\n",
      "\n",
      "subtract [3,5] [ 8. 19.]\n"
     ]
    }
   ],
   "source": [
    "# Inplace increase/decrease variable values\n",
    "\n",
    "f = tf.Variable(3.)\n",
    "print('\\noriginal value: ', f.numpy())\n",
    "f.assign(10)\n",
    "print('\\nassigned value: ', f.numpy())\n",
    "print('\\nadd 1:', f.assign_add(1.).numpy())\n",
    "print('\\nsubtract 5:', f.assign_sub(5.).numpy())\n",
    "\n",
    "# same but for arrays\n",
    "print(\"\\nIncrease/Decrease values in arrays\")\n",
    "print('original value: ',e.numpy())      \n",
    "print('\\nadd [1,4]: ', e.assign_add([1,4]).numpy())  \n",
    "print('\\nsubtract [3,5]', e.assign_sub([3,5]).numpy())  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<div align=\"center\" style=\"font-size:12px; font-family:FreeMono; font-weight: 100; font-stretch:ultra-condensed; line-height: 1.0; color:#2A2C2B\">\n",
    "    <img src=\"tF_update-09.png\" align=\"center\" width=\"50%\" padding=\"0px\"><br>\n",
    "    3D (Rank-3) Tensor\n",
    "</div>\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0  1  2  3  4]\n",
      "  [ 5  6  7  8  9]]\n",
      "\n",
      " [[10 11 12 13 14]\n",
      "  [15 16 17 18 19]]\n",
      "\n",
      " [[20 21 22 23 24]\n",
      "  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Tensors with 3 or more axes (dimensions)\n",
    "rank_3_tensor = tf.constant([\n",
    "  [[0, 1, 2, 3, 4],\n",
    "   [5, 6, 7, 8, 9]],\n",
    "  [[10, 11, 12, 13, 14],\n",
    "   [15, 16, 17, 18, 19]],\n",
    "  [[20, 21, 22, 23, 24],\n",
    "   [25, 26, 27, 28, 29]],])\n",
    "                    \n",
    "print(rank_3_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "##### <strong style=\"color:blue\">Concept Check:</strong>  Building high-dimensional tensors\n",
    "\n",
    "<br>\n",
    "\n",
    "<div align=\"center\" style=\"font-size:12px; font-family:FreeMono; font-weight: 100; font-stretch:ultra-condensed; line-height: 1.0; color:#2A2C2B\">\n",
    "    <img src=\"tF_update-08.png\" align=\"center\" width=\"50%\" padding=\"0px\"><br>\n",
    "    4D (Rank-4) Tensor\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "To test your understanding of Tensors, create the above Tensor. For simplicity, make all entries equal to zero and name your tensor as ```rank_4_tensor```. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sanity Check ##\n",
    "#print(\"\\nType of elements:\", rank_4_tensor.dtype)\n",
    "#print(\"\\nNumber of dimensions:\", rank_4_tensor.ndim)\n",
    "#print(\"\\nShape of tensor:\", rank_4_tensor.shape)\n",
    "#print(\"\\nElements along axis 0 of tensor:\", rank_4_tensor.shape[0])\n",
    "#print(\"\\nElements along the last axis of tensor:\", rank_4_tensor.shape[-1])\n",
    "#print(\"\\nTotal number of elements (3*2*4*5): \", tf.size(rank_4_tensor).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### **(Optional) Lifecycles, naming, and watching**\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to Python Objects, a ```tf.Variable``` instance has an [object lifecyle](https://en.wikipedia.org/wiki/Object_lifetime). For example, when there are no references to a variable it is automatically ignored and deallocated. Variable names are preserved when loading and saving models -- however, there is no need to assign them as variables in in models are uniquely named automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Altenatively, we can pass Python Lists or NumPy arrays\n",
    "my_tensor = tf.constant([[1.0, 2.0], [3.0, 4.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[False False]\n",
      " [False False]], shape=(2, 2), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "# Create a and b; they have the same value but are backed by different tensors.\n",
    "g = tf.Variable(my_tensor, name=\"Mark\")\n",
    "\n",
    "# A new variable with the same name, but different value\n",
    "h = tf.Variable(my_tensor + 1, name=\"Mark\")      # Note that the scalar add is broadcast (see intro_NUMPY for details)\n",
    "\n",
    "# These are elementwise-unequal, despite having the same name\n",
    "print(g == h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### **(Optional) Placing variables and tensors**\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow will always attempt to place tensors and variables on the fastest device compatible with the ```dtype```. However, this too is a process that can be overriden if desired. The following shows an example of such an instance. In particular, a float tensor and variable are placed on a CPU even if a GPU is available -- most variables are placed on a GPU if one is available. For more details on placing variables and tensors, see [here](https://www.tensorflow.org/guide/variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[22. 28.]\n",
      " [49. 64.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.device('CPU:0'):\n",
    "\n",
    "  # Create some tensors\n",
    "  i = tf.Variable([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "  j = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "  k = tf.matmul(i, j)\n",
    "\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "**Note:** Placing variables is an important aspect of TF. This is because it is possible to set the location of a variable or tensor on one device, yet do the computation on another device. This may introduce delay when devices communicate with one-another, but should you want to have multiple GPU workers yet only one copy of the variables this approach is worth considering. See [automatic distribution](https://www.tensorflow.org/guide/autodiff) for details.\n",
    "\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1.  4.  9.]\n",
      " [ 4. 10. 18.]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.device('CPU:0'):\n",
    "  l = tf.Variable([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "  m = tf.Variable([[1.0, 2.0, 3.0]])\n",
    "    \n",
    "with tf.device('GPU:0'):\n",
    "  # Element-wise multiply\n",
    "  n = l * m\n",
    "\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "**Note:** [tf.config.set_soft_device_placement](https://www.tensorflow.org/api_docs/python/tf/config/set_soft_device_placement) is on by default. If you run the code above on a device witout a GPU, the multiplication will be ran on the CPU.\n",
    "    \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## TensorFlow Operations\n",
    "\n",
    "<br>\n",
    "\n",
    "<div align=\"center\" style=\"font-size:12px; font-family:FreeMono; font-weight: 100; font-stretch:ultra-condensed; line-height: 1.0; color:#2A2C2B\">\n",
    "    <img src=\"tF_update-04.png\" align=\"center\" width=\"50%\" padding=\"0px\"><br>\n",
    "</div>\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### **Basic Arithmetic on Tensors**\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tensors\n",
    "a = tf.constant([[1, 2],\n",
    "                 [3, 4]])\n",
    "b = tf.constant([[10, 20],\n",
    "                 [30, 40]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[11 22]\n",
      " [33 44]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Addition\n",
    "print(tf.add(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[11 22]\n",
      " [33 44]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Alternatively, element-wise addition using operator overloading\n",
    "print(a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 10  40]\n",
      " [ 90 160]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Element-wise multiplication\n",
    "print(tf.multiply(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 10  40]\n",
      " [ 90 160]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Alternatively, element-wise multiplication using operator overloading\n",
    "print(a * b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 10  40]\n",
      " [ 90 160]]\n"
     ]
    }
   ],
   "source": [
    "# Use NumPy values\n",
    "import numpy as np\n",
    "\n",
    "ab = np.multiply(a, b)\n",
    "print(ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 70 100]\n",
      " [150 220]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "print(tf.matmul(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 70 100]\n",
      " [150 220]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Alternatively, Matrix multiplication\n",
    "print(a @ b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### **Tensor Operations**\n",
    "\n",
    "<div align=\"center\" style=\"font-size:12px; font-family:FreeMono; font-weight: 100; font-stretch:ultra-condensed; line-height: 1.0; color:#2A2C2B\">\n",
    "    <img src=\"tF_update-02.png\" align=\"center\" width=\"40%\" padding=\"0px\"><br>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "The following represent a few operations on tensors. For a comprehensive list see [here](https://www.tensorflow.org/api_docs/python/tf/Tensor).\n",
    "\n",
    "___\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor for analysis\n",
    "c = tf.constant([[3.0, 7.0], [10.0, 2.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(10.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Find the largest value\n",
    "print(tf.reduce_max(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 0], shape=(2,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# Find the index of the largest value\n",
    "print(tf.argmax(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.7986210e-02 9.8201376e-01]\n",
      " [9.9966466e-01 3.3535014e-04]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Compute the softmax\n",
    "print(tf.nn.softmax(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### **Gradients from scrach**\n",
    "\n",
    "> On the following examples, we are using [tf.GradientTape( )](https://www.tensorflow.org/api_docs/python/tf/GradientTape) to compute some example gradients. GradientTape is considered an advanced TensorFlow feature, but also an extremely powerful option for [advanced and custom differentiation](https://www.tensorflow.org/guide/advanced_autodiff).\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (6, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a noisy dataset that resembles y=mx+b+some_noise\n",
    "def noisy_data(m=0.3, b=.3, n=100):\n",
    "    x = tf.random.uniform(shape=(n,))\n",
    "    some_noise = tf.random.normal(shape=(len(x),), stddev=0.01)\n",
    "    y = m * x + b + some_noise\n",
    "    return(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some data\n",
    "x_train, y_train = noisy_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0552ad5630>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the data as scatter\n",
    "plt.plot(x_train, y_train, 'b.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare variables\n",
    "m = tf.Variable(0.)\n",
    "b = tf.Variable(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "def pred_response(x):\n",
    "    y = m * x + b\n",
    "    return(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "def squared_error(y_pred, y_act):\n",
    "    squaredError = tf.reduce_mean(tf.square(y_pred - y_act))\n",
    "    return(squaredError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loss:  0.21045142\n"
     ]
    }
   ],
   "source": [
    "# compute loss prior to training\n",
    "loss = squared_error(pred_response(x_train), y_train)\n",
    "print(\"Starting loss: \", loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step number: 0, has loss 0.210451\n",
      "Step number: 10, has loss 0.014691\n",
      "Step number: 20, has loss 0.001719\n",
      "Step number: 30, has loss 0.000777\n",
      "Step number: 40, has loss 0.000638\n",
      "Step number: 50, has loss 0.000562\n",
      "Step number: 60, has loss 0.000500\n",
      "Step number: 70, has loss 0.000447\n",
      "Step number: 80, has loss 0.000401\n",
      "Step number: 90, has loss 0.000361\n",
      "Step number: 100, has loss 0.000327\n",
      "Step number: 110, has loss 0.000298\n",
      "Step number: 120, has loss 0.000273\n",
      "Step number: 130, has loss 0.000251\n",
      "Step number: 140, has loss 0.000232\n",
      "Step number: 150, has loss 0.000216\n",
      "Step number: 160, has loss 0.000202\n",
      "Step number: 170, has loss 0.000190\n",
      "Step number: 180, has loss 0.000179\n",
      "Step number: 190, has loss 0.000171\n",
      "\n",
      "Gradient after 200 steps:  [<tf.Tensor: shape=(), dtype=float32, numpy=-0.0033376145>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0018107207>]\n"
     ]
    }
   ],
   "source": [
    "# gradient descent from scratch\n",
    "learning_rate = 0.05\n",
    "steps = 200\n",
    "\n",
    "for i in range(steps):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = pred_response(x_train)\n",
    "        loss = squared_error (predictions, y_train)\n",
    "    \n",
    "    # compute loss with respect to m and b\n",
    "    gradients = tape.gradient(loss, [m, b])\n",
    "    \n",
    "    m.assign_sub(gradients[0] * learning_rate)\n",
    "    b.assign_sub(gradients[1] * learning_rate)\n",
    "   \n",
    "    \n",
    "    # track steps\n",
    "    if i % 10 == 0:\n",
    "        print(\"Step number: %d, has loss %f\" % (i, loss.numpy()))\n",
    "\n",
    "\n",
    "print(\"\\nGradient after %d steps: \" % steps, gradients)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### **Data Selection: Indexing and Slicing a Tensor**\n",
    "\n",
    "<br>\n",
    "\n",
    "TensorFlow follows standard Python indexing rules. For details see: [Indexing Tensors](https://www.tensorflow.org/guide/tensor#indexing)\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Single-Axis Indexing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(12,), dtype=int32, numpy=array([ 0,  1,  2,  3,  5,  6,  7,  8, 10, 20, 30, 40], dtype=int32)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tensor = tf.constant([0, 1, 2, 3, 5, 6, 7, 8, 10, 20, 30, 40])\n",
    "my_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First: 0\n",
      "Second: 1\n",
      "Last: 40\n"
     ]
    }
   ],
   "source": [
    "# indexing with a sclar removes the dimension\n",
    "print(\"First:\", my_tensor[0].numpy())\n",
    "print(\"Second:\", my_tensor[1].numpy())\n",
    "print(\"Last:\", my_tensor[-1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Single-Axis Slicing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything: [ 0  1  2  3  5  6  7  8 10 20 30 40]\n",
      "Before 4: [2. 3. 4.]\n",
      "From 4 to the end: []\n",
      "From 2, before 8: [4.]\n",
      "Every other item: [2. 4.]\n",
      "Reversed: [4. 3. 2.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Everything:\", my_tensor[:].numpy())\n",
    "print(\"Before 4:\", rank_1_tensor[:4].numpy())\n",
    "print(\"From 4 to the end:\", rank_1_tensor[4:].numpy())\n",
    "print(\"From 2, before 8:\", rank_1_tensor[2:8].numpy())\n",
    "print(\"Every other item:\", rank_1_tensor[::2].numpy())\n",
    "print(\"Reversed:\", rank_1_tensor[::-1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "**Note:** Integer indexing removes the dimension, while range indexing (i.e. slice) keeps the dimension.\n",
    "    \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Multi-Axis Indexing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2.]\n",
      " [3. 4.]\n",
      " [5. 6.]]\n"
     ]
    }
   ],
   "source": [
    "# reusing rank-2 tensor from before\n",
    "print(rank_2_tensor.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n"
     ]
    }
   ],
   "source": [
    "# Pull out a single value from a 2-rank tensor\n",
    "print(rank_2_tensor[2, 1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second row: [3. 4.]\n",
      "Second column: [2. 4. 6.]\n",
      "Last row: [5. 6.]\n",
      "First item in last column: 2.0\n",
      "Skip the first row:\n",
      "[[3. 4.]\n",
      " [5. 6.]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get row and column tensors using combination of indexing and slices\n",
    "print(\"Second row:\", rank_2_tensor[1, :].numpy())\n",
    "print(\"Second column:\", rank_2_tensor[:, 1].numpy())\n",
    "print(\"Last row:\", rank_2_tensor[-1, :].numpy())\n",
    "print(\"First item in last column:\", rank_2_tensor[0, -1].numpy())\n",
    "print(\"Skip the first row:\")\n",
    "print(rank_2_tensor[1:, :].numpy(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### **Manipulating Tensor Shapes**\n",
    "\n",
    "<br>\n",
    "\n",
    "Performing a tensor [reshape](https://www.tensorflow.org/guide/tensor#manipulating_shapes) will work so long as the shape of the new tensor has the same number of elements. \n",
    "\n",
    "___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n"
     ]
    }
   ],
   "source": [
    "# Shape returns a `TensorShape` object that shows the size on each dimension\n",
    "var_x = tf.Variable(tf.constant([[1], [2], [3]]))\n",
    "print(var_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 1]\n"
     ]
    }
   ],
   "source": [
    "# Convert tensor object into a Python list\n",
    "print(var_x.shape.as_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n",
      "(1, 3)\n"
     ]
    }
   ],
   "source": [
    "# Reshape a tensor to a new shape by passing a list\n",
    "reshaped = tf.reshape(var_x, [1, 3])\n",
    "\n",
    "# sanity check\n",
    "print(var_x.shape)\n",
    "print(reshaped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### **(Optional) Broadcasting Tensors**\n",
    "\n",
    "<br>\n",
    "\n",
    "<div align=\"center\" style=\"font-size:12px; font-family:FreeMono; font-weight: 100; font-stretch:ultra-condensed; line-height: 1.0; color:#2A2C2B\">\n",
    "    <img src=\"tF_update-06.png\" align=\"center\" width=\"40%\" padding=\"0px\"><br>\n",
    "    Broadcasted Tensor\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "[Broadcasting](https://www.tensorflow.org/guide/tensor#broadcasting) in TensorFlow is borrowed directly from the notion of [NumPy Array Broadcasting](https://numpy.org/doc/stable/user/basics.broadcasting.html). The general idea is that, under certain conditions, a smaller tensor can be 'stretched' to fit larger tensors when running combined operations on both.  Following are some examples of this concept.\n",
    "\n",
    "___\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable declarations\n",
    "x = tf.constant([5, 7, 11])\n",
    "y = tf.constant(3)\n",
    "z = tf.constant([3, 3, 3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([15 21 33], shape=(3,), dtype=int32)\n",
      "tf.Tensor([15 21 33], shape=(3,), dtype=int32)\n",
      "tf.Tensor([15 21 33], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Same results\n",
    "print(tf.multiply(x, 3))\n",
    "print(x * y)\n",
    "print(x * z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 5 10 15 20]\n",
      " [ 7 14 21 28]\n",
      " [11 22 33 44]], shape=(3, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "## To really grasp the idea: without broadcasting ##\n",
    "x_stretch = tf.constant([[5, 5, 5, 5],\n",
    "                         [7, 7, 7, 7],\n",
    "                         [11, 11, 11, 11]])\n",
    "\n",
    "y_stretch = tf.constant([[1, 2, 3, 4],\n",
    "                         [1, 2, 3, 4],\n",
    "                         [1, 2, 3, 4]])\n",
    "\n",
    "# using operator overloading\n",
    "result = x_stretch * y_stretch\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 5]\n",
      " [ 7]\n",
      " [11]], shape=(3, 1), dtype=int32) \n",
      "\n",
      "tf.Tensor([1 2 3 4], shape=(4,), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[ 5 10 15 20]\n",
      " [ 7 14 21 28]\n",
      " [11 22 33 44]], shape=(3, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "## To really grasp the idea: with broadcasting ##\n",
    "# These are the same computations\n",
    "x = tf.reshape(x,[3,1])\n",
    "y = tf.range(1, 5)\n",
    "print(x, \"\\n\")\n",
    "print(y, \"\\n\")\n",
    "print(tf.multiply(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### **(Optional) Ragged, String, and Sparse Tensors**\n",
    "\n",
    "\n",
    "TensorFlow has several ways of dealing with 'abnormal' tensors. In particular:\n",
    "\n",
    "> [Ragged Tensors](https://www.tensorflow.org/guide/tensor#ragged_tensors) - variable number of element along some axis.<br>\n",
    "> [String Tensors](https://www.tensorflow.org/guide/tensor#string_tensors) - atomic dtype that cannot be indexed similar to Python strings.<br>\n",
    "> [Sparse Tensors](https://www.tensorflow.org/guide/tensor#sparse_tensors) - for handling sparse data, like a very wide embedding space.\n",
    "\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## TensorFlow Graphs and Executions\n",
    "\n",
    "<br>\n",
    "\n",
    "<div align=\"center\" style=\"font-size:12px; font-family:FreeMono; font-weight: 100; font-stretch:ultra-condensed; line-height: 1.0; color:#2A2C2B\">\n",
    "    <img src=\"tF_update-07.png\" align=\"center\" width=\"40%\" padding=\"0px\"><br>\n",
    "</div>\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### **TensorFlow Computation Function**\n",
    "\n",
    "<div align=\"center\" style=\"font-size:12px; font-family:FreeMono; font-weight: 100; font-stretch:ultra-condensed; line-height: 1.0; color:#2A2C2B\">\n",
    "    <img src=\"tF_update-01.png\" align=\"center\" width=\"50%\" padding=\"0px\"><br>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "In TensorFlow (TF) 2.0, you can decorate Python functions using ```tf.function``` to mark them for [just in time (JIT)](https://docs.w3cub.com/tensorflow~guide/performance/xla/jit/) compilation. Meaning that TensorFlow runs it as [single graph*](https://github.com/tensorflow/community/pull/20). This change is done to make TensorFlow more 'Pythonic' -- which enables eager execution by default, encourages the encapsulation of graph computations as Python functions, and aligns the 'state' in the TensorFlow runtime with the state in the Python program.  All that to say, **Functions, not sessions in TF 2.0**:\n",
    "\n",
    "```python\n",
    "    # TensorFlow 1.X\n",
    "    outputs = session.run(f(placeholder), feed_dict={placeholder: input})\n",
    "    # TensorFlow 2.0\n",
    "    outputs = f(input)\n",
    "```\n",
    "\n",
    "Just in case it wasn't clear, [using graphs directly is deprecated in TF 2.0](https://www.tensorflow.org/api_docs/python/tf/Graph#using_graphs_directly_deprecated)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### **TensorFlow Function -- \\@tf.function**\n",
    "\n",
    "The [\\@tf.function](https://www.tensorflow.org/api_docs/python/tf/function) compiles a function into a callable [TensorFlow graph](https://www.tensorflow.org/api_docs/python/tf/Graph).  Use the ```tf.function``` to get performant and portable models, but note that ```tf.function``` is not a one-size-fits-all solution for faster computation.  For more on common issues you may enconter when using ```tf.function``` and how to deal with them, see [here](https://www.tensorflow.org/guide/function#basics). Now let's get to some TF functions.\n",
    "\n",
    "___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example function\n",
    "@tf.function\n",
    "def f(x,y):\n",
    "    return(x ** 2 + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([2, 4])\n",
    "y = tf.constant([4, -2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([ 8, 14], dtype=int32)>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**\\@tf.function Control Flow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.function() may use data-dependent control flow \n",
    "@tf.function() \n",
    "def g(x):\n",
    "    if tf.reduce_sum(x) > 0:\n",
    "        return(x * x)\n",
    "    else: \n",
    "        return(-x // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=22.089998>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function call\n",
    "g(tf.constant(4.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "**Note:** ```tf.function()``` can handle ```if```, ```for```, ```while```, ```continue```, ```break```, and ```return``` control flow statements.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**\\@tf.function with** [**tf.Tensor**](https://www.tensorflow.org/api_docs/python/tf/Tensor) **and** [**tf.Variable**](https://www.tensorflow.org/api_docs/python/tf/Variable) **Objects**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def h():\n",
    "  return(x ** 2 - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([ 8, 18], dtype=int32)>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([-2, -4])\n",
    "y = tf.Variable([-4, -2])\n",
    "h()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**\\@tf.function with side effects, such as** [**tf.print**](https://www.tensorflow.org/api_docs/python/tf/print) **and** [**tf.Variable**](https://www.tensorflow.org/api_docs/python/tf/Variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def f_se(x):\n",
    "  for i in tf.range(x):\n",
    "    c.assign_add(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=4>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# before side-effects\n",
    "c = tf.Variable(4)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=7>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function call\n",
    "f_se(3)\n",
    "# after side-effects\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "**Key Point:** Any Python side-effects -- such as printing with ```print()```, appending to a list, etc. -- will only happen once as ```func```, in this case named ```f_se()```, is traced. If side-effects are desired in [tf.function](https://www.tensorflow.org/api_docs/python/tf/function), then they need to be written as TF ops. More on this below.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Handling side effects**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "\n",
    "# appends only once when tracing\n",
    "@tf.function\n",
    "def f(x):\n",
    "  for i in x:\n",
    "    l.append(i + 1)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function call\n",
    "f(tf.constant([2, 4, 9]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'while/add:0' shape=() dtype=int32>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine side-effects\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appends in tf.function\n",
    "@tf.function\n",
    "def f(x):\n",
    "  temp = tf.TensorArray(dtype=tf.int32, size=0, dynamic_size=True)\n",
    "  for i in range(len(x)):\n",
    "    temp = temp.write(i, x[i] + 1)\n",
    "  return(temp.stack())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([ 3,  5, 10], dtype=int32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function call\n",
    "f(tf.constant([2, 4, 9]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**\\@tf.function is Polymorphic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def g(x):\n",
    "  return(x + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([ 3,  5, 10], dtype=int32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function call with int32\n",
    "g(tf.constant([2, 4, 9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 3.,  5., 10.], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function call with floats32\n",
    "g(tf.constant([2.0, 4.0, 9.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "**Key Point:** [tf.function](https://www.tensorflow.org/api_docs/python/tf/function) can build more than one graph to support different data types or shapes as it encounters them. To obtain an individual graph, use the ```get_concrete_function``` method of the callable created by ```tf.function```. Example follows.\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source function for individual graph\n",
    "@tf.function\n",
    "def h(x):\n",
    "  return(tf.abs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 == f2? False\n"
     ]
    }
   ],
   "source": [
    "# Build individual graphs\n",
    "f1 = h.get_concrete_function(1)\n",
    "f2 = h.get_concrete_function(2)  # Slow \n",
    "print(\"f1 == f2?\", f1 is f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConcreteFunction h(x=1)\n",
      "  Returns:\n",
      "    int32 Tensor, shape=()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ConcreteFunction h(x=1) at 0x7F1E4026A080>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f1)\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConcreteFunction h(x=2)\n",
      "  Returns:\n",
      "    int32 Tensor, shape=()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ConcreteFunction h(x=2) at 0x7F1E40294438>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f2)\n",
    "f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 == f2? True\n",
      "ConcreteFunction h(x)\n",
      "  Args:\n",
      "    x: int32 Tensor, shape=()\n",
      "  Returns:\n",
      "    int32 Tensor, shape=()\n",
      "ConcreteFunction h(x)\n",
      "  Args:\n",
      "    x: int32 Tensor, shape=()\n",
      "  Returns:\n",
      "    int32 Tensor, shape=()\n"
     ]
    }
   ],
   "source": [
    "# Reuse graph created when f1 is traced\n",
    "f1 = h.get_concrete_function(tf.constant(1))\n",
    "f2 = h.get_concrete_function(tf.constant(2))  # Fast \n",
    "print(\"f1 == f2?\",f1 is f2)\n",
    "print(f1)\n",
    "print(f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**\\@tf.function with** [**Input Signatures**](https://www.python.org/dev/peps/pep-0362/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def f(x):\n",
    "  return(x + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different shapes\n",
    "vector = tf.constant([1.0, 1.0])\n",
    "matrix = tf.constant([[3.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 == f2? False\n",
      "ConcreteFunction f(x)\n",
      "  Args:\n",
      "    x: float32 Tensor, shape=(2,)\n",
      "  Returns:\n",
      "    float32 Tensor, shape=(2,)\n",
      "ConcreteFunction f(x)\n",
      "  Args:\n",
      "    x: float32 Tensor, shape=(1, 1)\n",
      "  Returns:\n",
      "    float32 Tensor, shape=(1, 1)\n"
     ]
    }
   ],
   "source": [
    "f1 = f.get_concrete_function(vector) \n",
    "f2 = f.get_concrete_function(matrix)\n",
    "\n",
    "print(\"f1 == f2?\", f1 is f2)\n",
    "print(f1)\n",
    "print(f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "**Key Point:** Recall that [tf.function](https://www.tensorflow.org/api_docs/python/tf/function) is polymorphic. As such, ```tf.function``` instantiates a separte graph for every unique input -- shape or datatypes. An [input signature](https://www.python.org/dev/peps/pep-0362/) can be provided to ```tf.function``` to control the graphs traced. This is useful to avoid creating multiple graphs when tensors have dynamic shapes, or to restrict the shape and datatype of tensors that can be used. Example follows.\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify previous function to include an input signature\n",
    "@tf.function(\n",
    "    input_signature=[tf.TensorSpec(shape=None, dtype=tf.float32)])\n",
    "def g(x):\n",
    "  return(x + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same shapes as before\n",
    "vector = tf.constant([1.0, 1.0])\n",
    "matrix = tf.constant([[3.0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 == f2? True\n",
      "<tensorflow.python.eager.function.ConcreteFunction object at 0x7f055259ff98>\n",
      "<tensorflow.python.eager.function.ConcreteFunction object at 0x7f055259ff98>\n"
     ]
    }
   ],
   "source": [
    "f1 = g.get_concrete_function(vector) \n",
    "f2 = g.get_concrete_function(matrix)\n",
    "\n",
    "print(\"f1 == f2?\", f1 is f2)\n",
    "print(f1)\n",
    "print(f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "___\n",
    "\n",
    "**Final Comments:** When using TF 2.0, it is recommended that users refactor their code into smaller functions that are called as needed. Moreover, it's not necessary to decorate each of these smaller functions with ```tf.function```; only use ```tf.function``` to decorate high-level computations -- for example, one step of training or the forward pass of your model.\n",
    "\n",
    "Also, when **creating variables** -- such as those created locally and returned -- keep in mind that a variable can only be created once. If you plan on creating local variables that are returned it is recommended to create stateful objecets like [tf.Variable](https://www.tensorflow.org/api_docs/python/tf/Variable) outside of [tf.function](https://www.tensorflow.org/api_docs/python/tf/function) and passing them as arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## References and Additional Resources\n",
    "___\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<div align=\"center\" style=\"font-size:12px; font-family:FreeMono; font-weight: 100; font-stretch:ultra-condensed; line-height: 1.0; color:#2A2C2B\">\n",
    "    <img src=\"tf_logo_social.png\" align=\"center\" width=\"30%\" padding=\"0px\"><br>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Install Python Development Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Install/Update pip3**\n",
    "\n",
    "https://pip.pypa.io/en/stable/installing/\n",
    "\n",
    "```bash\n",
    "    # TensorFlow requires pip version >= 19.0\n",
    "    $ pip install --upgrade pip \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Install/Update Python 3**\n",
    "\n",
    "https://www.python.org/downloads/\n",
    "\n",
    "```bash\n",
    "    # TensorFlow requires Python 3.5-3.8 \n",
    "    $ sudo apt-get update && sudo apt-get install python3-dev python3-pip python3-venv python-virtualenv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Creating a TensorFlow Virtual Environment (Recommended)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Create virtual environment**\n",
    "\n",
    ">On a terminal, or using magic keys, create a new virtual environment using a Python interpreter and creating a ```venv``` directory to hold it\n",
    "\n",
    "```bash\n",
    "    $ python3 -m venv venv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Activate the virtual environment**\n",
    "\n",
    "```bash\n",
    "    $ source ./venv/bin/activate      # sh, bash, or zsh\n",
    "\n",
    "    $ . ./venv/bin/activate.fish       # fish\n",
    "\n",
    "    $ source ./venv/bin/activate.csh  # csh or tcsh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Install packages within virtual environment**\n",
    "\n",
    "When the virtual environment is active, your shell prompt is prefixed by ```(venv)```\n",
    "\n",
    "> Step 1: reapeat 1.1.1 above, within ```(venv)```<br>\n",
    "\n",
    "```bash\n",
    "    # TensorFlow requires pip version >= 19.0\n",
    "    $ pip install --upgrade pip \n",
    "```    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Step 2: Install TensorFlow2\n",
    "\n",
    "```bash\n",
    "    (venv) $ pip install --upgrade tensorflow\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Step 3: Verify install\n",
    "\n",
    "```bash\n",
    "    (venv) $ python -c \"import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Step 4: To exit virtual enviroment later\n",
    "\n",
    "```bash\n",
    "    (venv) $ pip deactivate\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Install TensorFlow on Local Machine (Optional Setup)\n",
    "\n",
    "<br>\n",
    "\n",
    "**TensorFlow 2**\n",
    "\n",
    "https://www.tensorflow.org/install/pip\n",
    "\n",
    "```bash\n",
    "    # Install using pip\n",
    "    $ pip install --upgrade tensorflow \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Verify Installation**\n",
    "\n",
    "```bash\n",
    "    $ python -c \"import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Run TensorFlow in a Container (Optional Setup)\n",
    "\n",
    "[Tensorflow Docker images](https://www.tensorflow.org/install/docker) come pre-configured to run TensorFlow, and provide a virtual environment that is generally the easiest way to set up [GPU processing](https://www.tensorflow.org/install/gpu). To learn more about how to use [Docker](https://www.tensorflow.org/install/docker/) to separate your applications from your infrastructure, click [here](https://docs.docker.com/get-docker/).\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Additional Content and Sources\n",
    "\n",
    "> [TensorFlow Tutorials](https://pandas.pydata.org/pandas-docs/stable/user_guide/index.html)<br>\n",
    "> [TensorFlow Guide](https://youtu.be/dcqPhpY7tWk) <br>\n",
    "> [Deep Learning with Python by Francois Chollet](https://www.manning.com/books/deep-learning-with-python)\n",
    "> [Introduction to TensorFlow by Andrew Ng and Kian Katanforoosh](https://cs230.stanford.edu/blog/tensorflow/)<br>\n",
    "> [Deep Learning Illustrated by Jon Krohn, Grant Beyleveld, and Aglae Bassens](https://www.deeplearningillustrated.com/)<br>\n",
    "> [Hands-On Introduction to TensorFlow 2.0 by Josh Gordon and Amit Patankar](https://youtu.be/Yyv-ng0_OTU)<br>\n",
    "> [Getting Started with TensorFlow and Deep Learning by Josh Gordon](https://youtu.be/tYYVSEHq-io)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\"font-size:12px; font-family:FreeMono; font-weight: 100; font-stretch:ultra-condensed; line-height: 1.0; color:#2A2C2B\">\n",
    "    <img src=\"DataX_icon_wide_logo.png\" align=\"center\" width=\"50%\" padding=\"0px\"><br>\n",
    "    <br>\n",
    "</div>\n",
    "\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "livereveal": {
   "scroll": true
  },
  "rise": {
   "enable_chalkboard": true,
   "height": "90%",
   "width": "100%"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
